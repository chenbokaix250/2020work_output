# 卷积计算中的细节



**输入图片经过卷积后所得特征图大小的计算公式:**

* 输入图片大小 WxW
* Filter大小 FxF
* 步长 S
* padding的像素数 P

于是 可以得到:

N = (W - F + 2P)/S +1

输出图片大小为NxN

---

input__shape[10,3,227,227] 

output_num96

Filter(kernel_size) 11

S(strde) 4

N = (227 - 11 + 2x0)/4 +1 == 55

输出的特征图大小的shape为[10,96,55,55]



卷积核的个数等于输出特征图的通道数



**反卷积得到的图片大小计算方式:**

反卷积的大小是由卷积核大小与滑动步长决定,in是输入大小,k是卷积核大小,s是滑动步长,out是输出大小

得到out = (in - 1)*s +k

例如: 输入2x2 卷积核4x4 滑动步长 3 输出就是7x7

计算过程:(2-1)*3+4=7

看到转置卷积中存在指定padding的情况,如何计算特征图的大小.

out = (in - 1)*s - 2*p +k

池化得到的特征图大小计算方式:

卷积向下取整 池化向上取整

---

# 实例运用

### 05中的自编码器去噪模型

### 模型实现

定义模型的输入

```
from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D
from keras.models import Model, load_model

input_img = Input(shape=(28, 28, 1,))
复制代码
```

实现encoder部分，由两个`3*3*32`的卷积和两个`2*2`的最大池化组成

```
x = Conv2D(32, (3, 3), padding='same', activation='relu')(input_img)
x = MaxPooling2D((2, 2), padding='same')(x)
x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)
encoded = MaxPooling2D((2, 2), padding='same')(x)
复制代码
```

实现decoder部分，由两个`3*3*32`的卷积和两个`2*2`的上采样组成

```
# 7 * 7 * 32
x = Conv2D(32, (3, 3), padding='same', activation='relu')(encoded)
x = UpSampling2D((2, 2))(x)
x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)
x = UpSampling2D((2, 2))(x)
decoded = Conv2D(1, (3, 3), padding='same', activation='sigmoid')(x)
复制代码
```

## encode

input(shape=(28,28,1,)

28x28x1 表示数据是28x28的灰度图,最后一位空出表示数据个数(未定),所以是

```
N*28*28*1 --卷积--> 28*28*32(padding=same) --池化--> 14*14*32 --池化--> 7*7*32
```

## decode

`input 7*7*32`

```
7*7*32 --卷积--> 7*7*32 --上采样--> 14*14*32 --卷积-->14*14*32 --上采样--> 28*28*32 --卷积(Conv2D(1,(3,3))--> 28*28*1 
```



## 08中DCGAN模型

定义一些常量、网络输入、辅助函数

```
batch_size = 100
z_dim = 100
WIDTH = 64
HEIGHT = 64

OUTPUT_DIR = 'samples_' + dataset
if not os.path.exists(OUTPUT_DIR):
    os.mkdir(OUTPUT_DIR)

X = tf.placeholder(dtype=tf.float32, shape=[None, HEIGHT, WIDTH, 3], name='X')
noise = tf.placeholder(dtype=tf.float32, shape=[None, z_dim], name='noise')
is_training = tf.placeholder(dtype=tf.bool, name='is_training')

def lrelu(x, leak=0.2):
    return tf.maximum(x, leak * x)

def sigmoid_cross_entropy_with_logits(x, y):
    return tf.nn.sigmoid_cross_entropy_with_logits(logits=x, labels=y)
复制代码
```

生成器部分

```
def generator(z, is_training=is_training):
    momentum = 0.9
    with tf.variable_scope('generator', reuse=None):
        d = 4
        h0 = tf.layers.dense(z, units=d * d * 512)
        h0 = tf.reshape(h0, shape=[-1, d, d, 512])
        h0 = tf.nn.relu(tf.contrib.layers.batch_norm(h0, is_training=is_training, decay=momentum))
        
        h1 = tf.layers.conv2d_transpose(h0, kernel_size=5, filters=256, strides=2, padding='same')
        h1 = tf.nn.relu(tf.contrib.layers.batch_norm(h1, is_training=is_training, decay=momentum))
        
        h2 = tf.layers.conv2d_transpose(h1, kernel_size=5, filters=128, strides=2, padding='same')
        h2 = tf.nn.relu(tf.contrib.layers.batch_norm(h2, is_training=is_training, decay=momentum))
        
        h3 = tf.layers.conv2d_transpose(h2, kernel_size=5, filters=64, strides=2, padding='same')
        h3 = tf.nn.relu(tf.contrib.layers.batch_norm(h3, is_training=is_training, decay=momentum))
        
        h4 = tf.layers.conv2d_transpose(h3, kernel_size=5, filters=3, strides=2, padding='same', activation=tf.nn.tanh, name='g')
        return h4
```

```shell
d = 4 
h0[-1,4,4,512] 
--逆卷积filter256 strides 2--> 
h1[-1,8,8,256] 
--逆卷积filter128 strides 2-->
h2[-1,16,16,128] -
- 逆卷积filter64 strides2-->
h3[-1,32,32,64] 
--逆卷积filter3 strides 2 -->
h4[-1,64,64,3]
```

---

## acGAN

![preview](https://pic4.zhimg.com/v2-39df5ea8dc99d7faa6ba7a78504958fb_r.jpg)

```
128维随机噪音 和 34个条件
16*16*64(长宽16 深度64)
Elenmentwise Sum 将输出加在一起
残差快重复16次操作
shape 16*16*64  Conv的filter是64 所以16次操作后shape不改变 仍然是16*16*64
###
Conv后 16*16*256 pixel Shufflerx2-->32*32*64
经过3次 注意 这里的卷积filter是不随之变化的  总是256
time2时: Conv(3_256_1)后 32*32*256 pixel Shufflerx2-->64*64*64
time3时: Conv(3_256_1)后 64*64*256 pixel Shufflerx2-->128*128*64

Pixel Shuffle 将多个层拼接成一个层,从而达到增加高度和宽度,减少深度的目的

然后利用最后Conv(9_3_1)
变成128*128*3

```

---

## acGAN  again

![165f4c16ddc0c767.jpg](https://i.loli.net/2020/03/09/TywGF1SJiskUA9c.jpg)

```
input 128*128*3
Conv(4,32,2) --> shape 64*64*32
残差网络两个 相加不影响shape变化
Conv(4,64,2) --> shape 32*32*64
再走一遍之后
Conv(4,128,2) --> shape 16*16*128
Conv(3,256,2) --> shape 8*8*256
conv(3,512,2) --> shape 4*4*512
Conv(3,1024,2) --> shape 2*2*1024
最后得到Dense(1)和Dense(34)
```

## CycleGAN 网络结构

![img](https://user-gold-cdn.xitu.io/2018/9/20/165f4c99c2028e88?imageslim)



```
生成器:
input(256*256*3 --> 256*256*64 --> 128*_128*128 --> 64*64*256 --> 残差x9
--> 128*128*128 --> 256*256*64 --> 256*256*3 -->output

判别器:
input 256*256*3 --> 128*128*64 --> 64*64*128 --> 32*32*256 --> 16*16*512 --> 16*16*1(output)
```

